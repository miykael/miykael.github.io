<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Michael P. Notter


  | Age prediction of a speaker's voice

</title>
<meta name="description" content="Personal homepage of Michael P. Notter.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/monokai.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®‚Äçüíª</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://miykael.github.io/blog/2022/audio_eda_and_modeling/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://miykael.github.io/">
       <span class="font-weight-bold">Michael</span> P.  Notter
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/background/">
                Background
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      





<div class="post">

  <header class="post-header">
    <h1 class="post-title">Age prediction of a speaker's voice</h1>
    <p class="post-meta">February 16, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
      

      

    </p>
  </header>

  <article class="post-content">
    <h2 id="how-to-perform-eda-and-data-modeling-on-audio-data">How to perform EDA and data modeling on audio data</h2>

<p><em>[Find the Jupyter Notebook to this article <a href="https://github.com/miykael/miykael.github.io/blob/master/assets/nb/04_audio_data_analysis/nb_audio_eda_and_modeling.ipynb" target="_blank" rel="noopener noreferrer">here</a>.]</em></p>

<hr>

<p>Most people are familiar with how to run a data science project on image, text or tabular data. But not many have experience with analyzing audio data. In this article, we will learn how we can do exactly that. How to prepare, explore and analyze audio data with the help of machine learning. In short: As for all other modalities (e.g. text or images) as well, the trick is to get the data into a machine interpretable format.</p>

<p>The interesting thing with audio data is that you can treat it as many different modalities:</p>

<ul>
  <li>You can extract <strong>high-level</strong> features and analyze the data like <strong>tabular</strong> data.</li>
  <li>You can compute <strong>frequency plots</strong> and analyze the data like <strong>image</strong> data.</li>
  <li>You can use <strong>temporal sensitive models</strong> and analyze the data like <strong>time-series</strong> data.</li>
  <li>You can use <strong>speech-to-text models</strong> and analyze the data like <strong>text</strong> data.</li>
</ul>

<p>In this article we will look at the first three approaches. But first, let‚Äôs take a closer look at what audio data actually looks like.</p>

<h1 id="1-the-many-facets-of-audio-data">1. The many facets of audio data</h1>

<p>While there are multiple Python libraries that allow you to work with audio data, for this example, we will be using <a href="https://librosa.org/doc/main/index.html" target="_blank" rel="noopener noreferrer">librosa</a>. So, let‚Äôs load an MP3 file and plot its content.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use this code snippet to suppress all 'librosa' related UserWarnings
</span><span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">"</span><span class="s">ignore</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Import librosa
</span><span class="kn">import</span> <span class="n">librosa</span>

<span class="c1"># Loads mp3 file with a specific sampling rate, here 16kHz
</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">c4_sample-1.mp3</span><span class="sh">"</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>

<span class="c1"># Plot the signal stored in 'y'
</span><span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">librosa.display</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Audio signal as waveform</span><span class="sh">"</span><span class="p">)</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">waveplot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">);</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_3_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>What you see here is the <strong>waveform</strong> representation of the spoken sentence: ‚Äú<strong><em>he just got a new kite for his birthday</em></strong>‚Äù.</p>

<h2 id="11-waveform---signal-in-the-time-domain">1.1. Waveform - signal in the time-domain</h2>

<p>Before we called it time-series data, but now we name it waveform? Well, it‚Äôs both. This becomes clearer when we look only at a small segment of this audio file. The following illustration shows the same thing as above, but this time only 62.5 milliseconds of it.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">17500</span><span class="p">:</span><span class="mi">18500</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_6_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>What you can see is a temporal signal that oscillates around the value 0 with different frequencies and amplitudes.This signal represents the air pressure change over time, or the physical displacement of a loud speaker‚Äôs membrane (or the membrane in your ear for that matter). That‚Äôs why this depiction of the audio data is also called <strong>waveform</strong>.</p>

<p>The <strong>frequency</strong> is the speed with which this signal oscillates. Low frequency, e.g. 60 Hz could be the sound of bass guitar, while a birds song could be in the higher frequency of 8000 Hz. Human speech is usually anywhere between that.</p>

<p>To know how quickly this signal needs to be interpret, we also need to know the <strong>sampling rate</strong> at which the data was recorded. In this case, the sampling rate per second was 16‚Äô000 or 16k Hz. Which means that the 1‚Äô000 time points we can see in the previous figure represents 62.5 milliseconds (1000/16000 = 0.0625) of audio signal.</p>

<h2 id="12-the-fourier-transform---signal-in-the-frequency-domain">1.2. The Fourier Transform - signal in the frequency domain</h2>

<p>While the previous visualization can tell us when something happens (i.e. around 2 seconds there seem to be a lot of waveforms), it cannot really tell us with what frequency it happens. Because the waveform shows us information about the when, this signal is also said to be in the <strong>time domain</strong>.</p>

<p>Using a fast fourier transformation, we can invert this issue and get a clear information about what frequencies are present, while loosing all information about the when. In such a case, the signal representation is said to be in the <strong>frequency domain</strong>.</p>

<p>Let‚Äôs see what our spoken sentence from before looks like represented in the frequency domain.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">scipy</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Applies fast fourier transformation to the signal and takes absolute values
</span><span class="n">y_freq</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">scipy</span><span class="p">.</span><span class="n">fftpack</span><span class="p">.</span><span class="nf">fft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Establishes all possible frequency (dependent on the sampling rate and the length of the signal)
</span><span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">y_freq</span><span class="p">))</span>

<span class="c1"># Plot audio signal as frequency information.
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">semilogx</span><span class="p">(</span><span class="n">f</span><span class="p">[:</span> <span class="nf">len</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y_freq</span><span class="p">[:</span> <span class="nf">len</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Frequency (Hz)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_9_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>What you can see here is that most of the signal is somewhere between ~100 and ~1000 Hz (i.e. between $10^2$ and  $10^3$). Plus there seem to be some additional stuff from 1‚Äô000 to 10‚Äô000 Hz.</p>

<h2 id="13-spectrogram">1.3. Spectrogram</h2>

<p>Luckily, we don‚Äôt always need to decide for either the time or frequency domain. Using a <strong>spectrogram</strong> plot, we can profit from both domains, while keeping most of their handicaps minimal. There are multiple ways how you can create such spectrogram plots, but for this article let‚Äôs take a look at three in particular.</p>

<h3 id="131-short-time-fourier-transform-stft">1.3.1. Short-time Fourier transform (STFT)</h3>

<p>Using a small adapted version of the fast fourier transformation before, namely the <strong>short-time fourier transformation</strong> (STFT), we can create such a spectrogram. The small trick that is applied here is that the FFT is computed for multiple small time windows (hence ‚Äúshort-time fourier‚Äù) in a sliding window manner.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">librosa.display</span>

<span class="c1"># Compute short-time Fourier Transform
</span><span class="n">x_stft</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">librosa</span><span class="p">.</span><span class="nf">stft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB
</span><span class="n">x_stft</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">amplitude_to_db</span><span class="p">(</span><span class="n">x_stft</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>

<span class="c1"># Plot STFT spectrogram
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">x_stft</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">log</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">%+2.0f dB</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_13_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>As in all spectrogram plots, the color represents the amount (loudness/volume) of a given frequency, at a given timepoint. +0dB is the loudest, and -80dB is close to silence. On the horizontal x-axis we can see the time, while on the vertical y-axis we can see the different frequencies.</p>

<h3 id="132-mel-spectrogram">1.3.2. Mel spectrogram</h3>

<p>As an alternative to the STFT, you can also compute the <strong>mel spectrogram</strong>, which is based on the <a href="https://en.wikipedia.org/wiki/Mel_scale" target="_blank" rel="noopener noreferrer">mel scale</a>. This scale accounts for the way we human perceive a sound‚Äôs pitch. The mel scale is calculated so that two pairs of frequencies separated by a delta in the mel scale are perceived by humans as having the same perceptual difference.</p>

<p>The mel spectrogram is computed very similar to the STFT, the main difference is just that the y-axis uses a different scale.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Compute the mel spectrogram
</span><span class="n">x_mel</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">melspectrogram</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">)</span>

<span class="c1"># Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB
</span><span class="n">x_mel</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">power_to_db</span><span class="p">(</span><span class="n">x_mel</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>

<span class="c1"># Plot mel spectrogram
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">x_mel</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">mel</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="sh">"</span><span class="s">%+2.0f dB</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_16_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>The difference to the STFT might not be too obvious first, but if you take a closer look, you can see that in the STFT plot, the frequency from 0 to 512 Hz take much more space on the y-axis than in the mel plot.</p>

<h3 id="133-mel-frequency-cepstral-coefficients-mfccs">1.3.3. Mel-frequency cepstral coefficients (MFCCs)</h3>

<p>The <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum" target="_blank" rel="noopener noreferrer">Mel-frequency cepstral coefficients</a> (MFCCs) are an alternative representation of the mel spectrogram from before. The advantage of the MFCCs over the mel-spectrogram are the rather small number of features (i.e. unique horizontal lines), usually ~20.</p>

<p>Due to the fact that the mel spectrogram is closer to the way we human perceive pitch and that the MFCCs only has a few number of component features, most machine learning practitioner prefer the MFCCs way of representing audio data in an ‚Äòimage way‚Äô. Which isn‚Äôt to say that for a given problem an STFT, mel or waveform representation might work better.</p>

<p>So, lets go ahead and compute the MFCCs and plot them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Extract 'n_mfcc' numbers of MFCCs components (here 20)
</span><span class="n">x_mfccs</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">mfcc</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># Plot MFCCs
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">x_mfccs</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_19_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<h1 id="2-data-cleaning">2. Data cleaning</h1>

<p>Now that we understand a bit better what audio data looks like, let‚Äôs visualize a few more examples. <strong>Note:</strong> You can download these four examples via these links: <a href="https://www.dropbox.com/scl/fi/zk1pavpavoifw7r3ek8ac/c4_sample-1.mp3?rlkey=chvsev8wrkn4mrnwwz5o8kgnd&amp;dl=1" target="_blank" rel="noopener noreferrer">Audio 1</a>, <a href="https://www.dropbox.com/scl/fi/ls71sjgcc7j3jtsz4bbxp/c4_sample-2.mp3?rlkey=qbe9dh2548r7juji7xo7kh465&amp;dl=1" target="_blank" rel="noopener noreferrer">Audio 2</a>, <a href="https://www.dropbox.com/scl/fi/jyxonbiv82nsulmnc415h/c4_sample-3.mp3?rlkey=q7icmpyd5io0n3apnlk6thsys&amp;dl=1" target="_blank" rel="noopener noreferrer">Audio 3</a>, <a href="https://www.dropbox.com/scl/fi/b0mxezlc5wqgp8fqzjcfz/c4_sample-4.mp3?rlkey=dg94biwlrxr46rg3t43tofbna&amp;dl=1" target="_blank" rel="noopener noreferrer">Audio 4</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Visualization of four mp3 files
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()):</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="sh">"</span><span class="s">c4_sample-%d.mp3</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>
    <span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">waveplot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_21_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>From these four examples, and more importantly, when listening to them, we can gather a few more insights about this audio dataset:</p>

<ol>
  <li>Most recordings have a long silence period at the beginning and the end of the recording (see sample 1 and 2). This is something we should take care of with ‚Äòtrimming‚Äô.</li>
  <li>However, in some cases, these silence period are interrupted by a ‚Äòclick‚Äô, due to the pressing and releasing of the recording buttons (see sample 2).</li>
  <li>Some audio recording don‚Äôt have such silence phase, i.e. a straight line (see sample 3 and 4). When listening to these recordings we can observe that this is due to a lot of background noise.</li>
</ol>

<p>To better understand how this is represented in the frequency domain, let‚Äôs look at the corresponding STFT spectrograms.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The code is the same as before, using the stft-spectrogram routine
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()):</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="sh">"</span><span class="s">c4_sample-%d.mp3</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>
    <span class="n">x_stft</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">librosa</span><span class="p">.</span><span class="nf">stft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">x_stft</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">amplitude_to_db</span><span class="p">(</span><span class="n">x_stft</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>
    <span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">x_stft</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">log</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_23_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>When we listen to the audio recordings we can observe that sample 3 has varying background noise covering multiple frequencies, while the background noise in sample 4 is rather constant. This is also what we see in the figures above. Sample 3 is very noisy throughout, while sample 4 is noisy only on a few frequencies (i.e. the thick horizontal lines). For now we won‚Äôt go into detail of how such noise could be removed, as this would be beyond the scope of this article.</p>

<p>So, let‚Äôs look into a ‚Äòshort-cut‚Äô of how we could remove such noise, and trim the audio samples. While a more manual approach, using custom filtering functions, might be the best approach to remove noise from audio data, in our case we will go ahead and use the practical python package <a href="https://github.com/timsainb/noisereduce" target="_blank" rel="noopener noreferrer">noisereduce</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">noisereduce</span> <span class="k">as</span> <span class="n">nr</span>
<span class="kn">from</span> <span class="n">scipy.io</span> <span class="kn">import</span> <span class="n">wavfile</span>

<span class="c1"># Loop through all four samples
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>

    <span class="c1"># Load audio file
</span>    <span class="n">fname</span> <span class="o">=</span> <span class="sh">"</span><span class="s">c4_sample-%d.mp3</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>

    <span class="c1"># Remove noise from audio sample
</span>    <span class="n">reduced_noise</span> <span class="o">=</span> <span class="n">nr</span><span class="p">.</span><span class="nf">reduce_noise</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">stationary</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="c1"># Save output in a wav file as mp3 cannot be saved to directly
</span>    <span class="n">wavfile</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">fname</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">.mp3</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">.wav</span><span class="sh">"</span><span class="p">),</span> <span class="n">sr</span><span class="p">,</span> <span class="n">reduced_noise</span><span class="p">)</span>
</code></pre></div></div>

<p>If you listen to the created wav files, you can hear that the noise is almost completely gone. Yes, we also introduced a few more artifacts, but overall, we hope that our noise removal approach did more good than harm.</p>

<p>For the trimming step we can use librosa‚Äôs <code class="language-plaintext highlighter-rouge">.effects.trim()</code> function. Note, each dataset might need a different <code class="language-plaintext highlighter-rouge">top_db</code> parameter for the trimming, so best is to try out a few versions and see what works well. In our case it is <code class="language-plaintext highlighter-rouge">top_db=20</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loop through all four samples
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>

    <span class="c1"># Load audio file
</span>    <span class="n">fname</span> <span class="o">=</span> <span class="sh">"</span><span class="s">c4_sample-%d.wav</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>

    <span class="c1"># Trim signal
</span>    <span class="n">y_trim</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">effects</span><span class="p">.</span><span class="nf">trim</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">top_db</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="c1"># Overwrite previous wav file
</span>    <span class="n">wavfile</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">fname</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">.mp3</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">.wav</span><span class="sh">"</span><span class="p">),</span> <span class="n">sr</span><span class="p">,</span> <span class="n">y_trim</span><span class="p">)</span>
</code></pre></div></div>

<p>Let‚Äôs now take another look at the cleaned data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()):</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="sh">"</span><span class="s">c4_sample-%d.wav</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>
    <span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">waveplot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_29_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>Much better!</p>

<h1 id="3-feature-extraction">3. Feature extraction</h1>

<p>Now that our data is clean, let‚Äôs go ahead and look into a few audio-specific feature that we could extract. But first, let‚Äôs load a file.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load data for sample 1
</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">c4_sample-1.wav</span><span class="sh">"</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="31-onset-detection">3.1. Onset detection</h2>

<p>Looking at the waveform of a signal, librosa can reasonably well identify the onset of a new spoken word.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Extract onset timestamps of words
</span><span class="n">onsets</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">onset</span><span class="p">.</span><span class="nf">onset_detect</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">backtrack</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Plot onsets together with waveform plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">waveplot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">onsets</span><span class="p">:</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">vlines</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Return number of onsets
</span><span class="n">number_of_words</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">onsets</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">number_of_words</span><span class="si">}</span><span class="s"> onsets were detected in this audio signal.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_34_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<pre><code class="language-code">7 onsets were detected in this audio signal
</code></pre>

<h2 id="32-length-of-an-audio-recording">3.2. Length of an audio recording</h2>

<p>Very much related to this is the length of an audio recording. The longer the recording, the more words can be spoken. So let‚Äôs compute the length of the recording and the speed at which words are spoken.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Computes duration in seconds
</span><span class="n">duration</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">sr</span>
<span class="n">words_per_second</span> <span class="o">=</span> <span class="n">number_of_words</span> <span class="o">/</span> <span class="n">duration</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">The audio signal is </span><span class="si">{</span><span class="n">duration</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds long,
with an average of </span><span class="si">{</span><span class="n">words_per_second</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> words per seconds.</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-code">The audio signal is 1.70 seconds long,
with an average of 4.13 words per seconds.
</code></pre>

<h2 id="33-tempo">3.3. Tempo</h2>

<p>Language is a very melodic signal, and each of us has a unique way and speed of speaking. Therefore, another feature that we could extract is the tempo of our speech, i.e. the number of beats that can be detected in an audio signal.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Computes the tempo of a audio recording
</span><span class="n">tempo</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">beat</span><span class="p">.</span><span class="nf">tempo</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">start_bpm</span><span class="o">=</span><span class="mi">10</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">The audio signal has a speed of </span><span class="si">{</span><span class="n">tempo</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> bpm.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-code">The audio signal has a speed of 42.61 bpm.
</code></pre>

<h2 id="34-fundamental-frequency">3.4. Fundamental frequency</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Fundamental_frequency" target="_blank" rel="noopener noreferrer">fundamental frequency</a> is the lowest frequency at which a periodic sound appears. In music this is also known as pitch. In the spectrogram plots that we saw before, the fundamental frequency (also called f0) is the lowest bright horizontal strip in the image. While the repetition of the strip pattern above this fundamental are called harmonics.</p>

<p>To better illustrate what we exactly mean, let‚Äôs extract the fundamental frequency and plot them in our spectrogram.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Extract fundamental frequency using a probabilistic approach
</span><span class="n">f0</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">pyin</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">fmin</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">fmax</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">frame_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>

<span class="c1"># Establish timepoint of f0 signal
</span><span class="n">timepoints</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">f0</span><span class="p">),</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Plot fundamental frequency in spectrogram plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x_stft</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">librosa</span><span class="p">.</span><span class="nf">stft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="n">x_stft</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">amplitude_to_db</span><span class="p">(</span><span class="n">x_stft</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">x_stft</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">log</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">timepoints</span><span class="p">,</span> <span class="n">f0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">cyan</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_40_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>The turquoise lines that you see around 100 Hz are the fundamental frequencies. So, this seems about write. But how can we now use that for feature engineering? Well, what we could do is compute specific characteristics of this f0.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Computes mean, median, 5%- and 95%-percentile value of fundamental frequency
</span><span class="n">f0_values</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="p">.</span><span class="nf">nanmean</span><span class="p">(</span><span class="n">f0</span><span class="p">),</span>
    <span class="n">np</span><span class="p">.</span><span class="nf">nanmedian</span><span class="p">(</span><span class="n">f0</span><span class="p">),</span>
    <span class="n">np</span><span class="p">.</span><span class="nf">nanstd</span><span class="p">(</span><span class="n">f0</span><span class="p">),</span>
    <span class="n">np</span><span class="p">.</span><span class="nf">nanpercentile</span><span class="p">(</span><span class="n">f0</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">np</span><span class="p">.</span><span class="nf">nanpercentile</span><span class="p">(</span><span class="n">f0</span><span class="p">,</span> <span class="mi">95</span><span class="p">),</span>
<span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"""</span><span class="s">This audio signal has a mean of {:.2f}, a median of {:.2f}, a
std of {:.2f}, a 5-percentile at {:.2f} and a 95-percentile at {:.2f}.</span><span class="sh">"""</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">*</span><span class="n">f0_values</span><span class="p">))</span>
</code></pre></div></div>

<pre><code class="language-code">This audio signal has a mean of 81.98, a median of 80.46, a
std of 4.42, a 5-percentile at 76.57 and a 95-percentile at 90.64.
</code></pre>

<p><strong>Note:</strong> There are of course many more audio feature extraction techniques that you could explore. For a nice summary
of a few of them, check out <a href="https://musicinformationretrieval.com/#Signal-Analysis-and-Feature-Extraction" target="_blank" rel="noopener noreferrer">musicinformationretrieval.com</a>.</p>

<h1 id="4-exploratory-data-analysis-eda-on-audio-dataset">4. Exploratory data analysis (EDA) on audio dataset</h1>

<p>Now that we know what audio data looks like and how we can process it, let‚Äôs go a step further and conduct a proper EDA on it. To do so, let‚Äôs first download a dataset. <strong>Note</strong>, the dataset we will be using for this article was downloaded from the <a href="https://www.kaggle.com/mozillaorg/common-voice" target="_blank" rel="noopener noreferrer">Common Voice</a> repository from Kaggle. This 14 GB big dataset is only a small snapshot of a +70 GB big dataset from <a href="https://commonvoice.mozilla.org/en/datasets" target="_blank" rel="noopener noreferrer">Mozilla</a>. But don‚Äôt worry, for our example here we will use an ever smaller subsample of roughly ~9‚Äô000 audio files.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Download and unzip dataset
</span><span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">qO</span> <span class="n">c4_audio_dataset</span><span class="p">.</span><span class="nb">zip</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">dropbox</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">s</span><span class="o">/</span><span class="n">tkqpq16cu4i1oyd</span><span class="o">/</span><span class="n">c4_audio_dataset</span><span class="p">.</span><span class="nb">zip</span><span class="err">?</span><span class="n">dl</span><span class="o">=</span><span class="mi">1</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">q</span> <span class="n">c4_audio_dataset</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">rm</span> <span class="n">c4_audio_dataset</span><span class="p">.</span><span class="nb">zip</span>
</code></pre></div></div>

<p>So let‚Äôs take a closer look at this dataset and some already extracted features.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Load the csv-file which contains already extracted features
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">c4_common-voice_dataset.csv.zip</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>filename</th>
      <th>age</th>
      <th>gender</th>
      <th>nwords</th>
      <th>duration</th>
      <th>words_per_second</th>
      <th>tempo</th>
      <th>f0_mean</th>
      <th>f0_median</th>
      <th>f0_std</th>
      <th>f0_5perc</th>
      <th>f0_95perc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sample_00001.mp3</td>
      <td>thirties</td>
      <td>male</td>
      <td>7</td>
      <td>2.628</td>
      <td>2.663</td>
      <td>25.000</td>
      <td>102.324</td>
      <td>98.498</td>
      <td>17.991</td>
      <td>80.418</td>
      <td>132.998</td>
    </tr>
    <tr>
      <td>sample_00002.mp3</td>
      <td>sixties</td>
      <td>male</td>
      <td>15</td>
      <td>2.916</td>
      <td>5.144</td>
      <td>27.173</td>
      <td>97.773</td>
      <td>96.799</td>
      <td>17.866</td>
      <td>70.626</td>
      <td>129.735</td>
    </tr>
    <tr>
      <td>sample_00003.mp3</td>
      <td>twenties</td>
      <td>female</td>
      <td>18</td>
      <td>3.528</td>
      <td>5.102</td>
      <td>25.000</td>
      <td>237.412</td>
      <td>234.253</td>
      <td>36.550</td>
      <td>185.338</td>
      <td>301.256</td>
    </tr>
    <tr>
      <td>sample_00004.mp3</td>
      <td>twenties</td>
      <td>male</td>
      <td>35</td>
      <td>6.516</td>
      <td>5.371</td>
      <td>21.306</td>
      <td>189.364</td>
      <td>110.553</td>
      <td>196.566</td>
      <td>90.317</td>
      <td>689.908</td>
    </tr>
    <tr>
      <td>sample_00005.mp3</td>
      <td>fourties</td>
      <td>female</td>
      <td>19</td>
      <td>5.040</td>
      <td>3.769</td>
      <td>19.531</td>
      <td>204.885</td>
      <td>202.755</td>
      <td>21.037</td>
      <td>177.839</td>
      <td>245.332</td>
    </tr>
  </tbody>
</table>
</div>

<p><br></p>

<h2 id="41-investigation-of-features-distribution">4.1. Investigation of features distribution</h2>

<h3 id="411-target-features">4.1.1. Target features</h3>

<p>First, let‚Äôs look at the class distributions of our potential target classes <code class="language-plaintext highlighter-rouge">age</code> and <code class="language-plaintext highlighter-rouge">gender</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">([</span><span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">]):</span>
    <span class="n">df</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">().</span><span class="n">plot</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_50_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p><br></p>

<h3 id="412-extracted-features">4.1.2. Extracted features</h3>

<p>As a next step, let‚Äôs take a closer look at the value distributions of the extracted features.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot value distributions of extracted features
</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">filename</span><span class="sh">"</span><span class="p">]).</span><span class="nf">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_52_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>Except for <code class="language-plaintext highlighter-rouge">words_per_second</code>, most of these feature distributions are right skewed and therefore could profit from a log-transformation. So let‚Äôs take care of that.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Applies log1p on features that are not age, gender, filename or words_per_second
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">log1p</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">filename</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">words_per_second</span><span class="sh">"</span><span class="p">]</span>
    <span class="k">else</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Let's look at the distribution once more
</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">filename</span><span class="sh">"</span><span class="p">]).</span><span class="nf">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_54_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>Much better, but what is interesting is the fact that the <code class="language-plaintext highlighter-rouge">f0</code> features all seem to have a bimodal distribution. Let‚Äôs plot the same thing as before, but this time separated by gender.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">gender</span><span class="p">.</span><span class="nf">unique</span><span class="p">():</span>
    <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">].</span><span class="nf">eq</span><span class="p">(</span><span class="n">g</span><span class="p">)][</span><span class="sh">"</span><span class="s">f0_median</span><span class="sh">"</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span>
        <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">g</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_56_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>As suspected, there seems to be a gender effect here! But what we can also see is that some <code class="language-plaintext highlighter-rouge">f0</code> scores (here in particular in males) are much lower and higher than they should be. These could potentially be outliers, due to bad feature extraction. Let‚Äôs take a closer look at all data points with the following figure.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot sample points for each feature individually
</span><span class="n">df</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">,</span> <span class="n">subplots</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">),</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_58_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>Given the few number of features and the fact that we have rather nice looking distributions with pronounced tails, we could go through each of them and decide the outlier cut off threshold feature by feature. But to show you a more automated way, lets use a z-score approach instead.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>

<span class="c1"># Only select columns with numbers from the dataframe
</span><span class="n">df_num</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">select_dtypes</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">number</span><span class="p">)</span>

<span class="c1"># Apply zscore to all numerical features
</span><span class="n">df_num</span> <span class="o">=</span> <span class="n">df_num</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">zscore</span><span class="p">)</span>

<span class="c1"># Identify all samples that are below a specific z-value
</span><span class="n">z_thresh</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">df_num</span><span class="p">.</span><span class="nf">abs</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">z_thresh</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Only keep the values in the mask
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<pre><code class="language-code">(8669, 12)
</code></pre>

<p>As you can see, this approach reduced our dataset roughly by 5%, which should be fine.</p>

<h2 id="42-feature-correlation">4.2. Feature correlation</h2>

<p>As a next step, let‚Äôs take a look at the correlation between all features. But before we can do that, let‚Äôs go ahead and also encode the non-numerical target features. Note, we could use scikit-learn‚Äôs <code class="language-plaintext highlighter-rouge">OrdinalEncoder</code> to do that, but that would potentially disrupt the correct order in the age feature. So let‚Äôs rather perform a manual mapping.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Map age to appropriate numerical value
</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">({</span>
        <span class="sh">"</span><span class="s">teens</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">twenties</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">thirties</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">fourties</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">fifties</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">sixties</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>

<span class="c1"># Map gender to corresponding numerical value
</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">({</span><span class="sh">"</span><span class="s">male</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">female</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</code></pre></div></div>

<p>Now we‚Äôre good to go to use pandas <code class="language-plaintext highlighter-rouge">.corr()</code> function together with seaborn‚Äôs <code class="language-plaintext highlighter-rouge">heatmap()</code> to gain more insight about the feature correlation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">df_corr</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">df_corr</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="sh">"</span><span class="s">.0f</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">mask</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df_corr</span><span class="p">)),</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">();</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_65_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>Interesting! What we can see is that our extracted <code class="language-plaintext highlighter-rouge">f0</code> features seem to have a rather strong relationship to <code class="language-plaintext highlighter-rouge">gender</code> target, while <code class="language-plaintext highlighter-rouge">age</code> doesn‚Äôt seem to correlate much with anything.</p>

<h2 id="43-spectrogram-features">4.3. Spectrogram features</h2>

<p>For now we haven‚Äôt looked at the actual audio recordings during our EDA. As we saw before, we have a lot of options (i.e. in waveform or as STFT, mel or mfccs spectrogram). For this exploration here, let‚Äôs go ahead look at the mel spectrograms.</p>

<p><strong>However</strong>, before we can do that we need to consider one thing: The audio samples are all of different length, meaning that the spectrograms will also have different length. Therefore, to normalize all recordings, let‚Äôs put cut them to a length of exactly 3 second. Meaning, samples that are too short will be filled up, while samples that are too long will be cut.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Two helper functions for audio data preparation
</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">librosa</span>

<span class="k">def</span> <span class="nf">resize_spectrogram</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">fact</span><span class="o">=-</span><span class="mi">80</span><span class="p">):</span>

    <span class="c1"># Create an empty canvas to put spectrogram into
</span>    <span class="n">canvas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">spec</span><span class="p">),</span> <span class="n">length</span><span class="p">))</span> <span class="o">*</span> <span class="n">fact</span>

    <span class="k">if</span> <span class="n">spec</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">length</span><span class="p">:</span>
        <span class="n">canvas</span><span class="p">[:,</span> <span class="p">:</span> <span class="n">spec</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">spec</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">canvas</span><span class="p">[:,</span> <span class="p">:</span><span class="n">length</span><span class="p">]</span> <span class="o">=</span> <span class="n">spec</span><span class="p">[:,</span> <span class="p">:</span><span class="n">length</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">canvas</span>

<span class="k">def</span> <span class="nf">compute_mel_spec</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16_000</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>

    <span class="c1"># Loads the mp3 file
</span>    <span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="sh">"</span><span class="s">audio_dataset</span><span class="sh">"</span><span class="p">,</span> <span class="n">filename</span><span class="p">),</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">)</span>

    <span class="c1"># Compute the mel spectrogram
</span>    <span class="n">x_mel</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">melspectrogram</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">)</span>

    <span class="c1"># Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB
</span>    <span class="n">x_mel</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">power_to_db</span><span class="p">(</span><span class="n">x_mel</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>

    <span class="c1"># Compute mean strength per frequency for mel spectrogram
</span>    <span class="n">mel_strength</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">x_mel</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Estimate the desired length of the spectrogram
</span>    <span class="n">length</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">duration</span> <span class="o">*</span> <span class="n">sr</span> <span class="o">/</span> <span class="n">hop_length</span><span class="p">)</span>

    <span class="c1"># Put mel spectrogram into the right shape
</span>    <span class="n">x_mel</span> <span class="o">=</span> <span class="nf">resize_spectrogram</span><span class="p">(</span><span class="n">x_mel</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">fact</span><span class="o">=-</span><span class="mi">80</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x_mel</span><span class="p">,</span> <span class="n">mel_strength</span>
</code></pre></div></div>

<p>Now that everything is ready, let‚Äôs extract the spectrograms for all audio samples.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Create arrays to store output into
</span><span class="n">spec_infos</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop through all files and extract spectrograms
</span><span class="n">sr</span> <span class="o">=</span> <span class="mi">16_000</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">spec_infos</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">compute_mel_spec</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">))</span>

<span class="c1"># Aggregate feature types in common variable
</span><span class="n">mels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">spec_infos</span><span class="p">])</span>
<span class="n">mels_strengths</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">spec_infos</span><span class="p">])</span>
</code></pre></div></div>

<p>Now that we have these spectrogram features as well, let‚Äôs perform some EDA on them too! And because we saw that ‚Äògender‚Äô seems to have a special relationship to our audio recordings, let‚Äôs visualize the average mel spectrogram for both gender separately, as well as their differences.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">librosa.display</span>

<span class="c1"># Creates a figure with two subplot
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># Plots mel spectrogram for male speakers
</span><span class="n">mels_male</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">mels</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">].</span><span class="nf">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">mels_male</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">mel</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">male</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Plots mel spectrogram for female speakers
</span><span class="n">mels_female</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">mels</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">gender</span><span class="sh">"</span><span class="p">].</span><span class="nf">eq</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span><span class="n">mels_female</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">mel</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">female</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Plot gender differences
</span><span class="n">librosa</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="nf">specshow</span><span class="p">(</span>
    <span class="n">mels_male</span> <span class="o">-</span> <span class="n">mels_female</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">time</span><span class="sh">"</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">=</span><span class="sh">"</span><span class="s">mel</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Difference</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_72_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>While it is difficult to see in the individual plot, the difference plot reveals that male speaker have on average lower voices than female. This can be seen by more strength in the lower frequencies (seeing in the red horizontal region) in the difference plot.</p>

<h1 id="5-machine-learning-models">5. Machine learning models</h1>

<p>Now, we‚Äôre ready for the modeling part. And as such, we have multiple options. With regards to <strong>models</strong>, we could ‚Ä¶</p>

<ul>
  <li>train our own classical (i.e. shallow) machine learning models, such as LogisticRegression or SVC.</li>
  <li>train our own deep learning models, i.e. deep neural network.</li>
  <li>use a pretrained neural network from TensorflowHub for feature extraction and then train a shallow or deep model on these high-level features</li>
</ul>

<p>And with regards to <strong>data</strong>, we could use ‚Ä¶</p>

<ul>
  <li>the data from the CSV file, combine it with the ‚Äòmel strength‚Äô features from the spectrograms and consider the data as a <em>tabular</em> data set</li>
  <li>the mel-spectrograms alone and consider them as a <em>image</em> data set</li>
  <li>the high-level features from TensorflowHub, combine them with the other tabular data and consider it as a <em>tabular</em> data set as well</li>
</ul>

<p>There are of course many different approaches and other ways to create the data set for the modeling part. For this article, let‚Äôs briefly explore one of them.</p>

<h2 id="classical-ie-shallow-machine-learning-model">Classical (i.e. shallow) machine learning model</h2>

<p>Let‚Äôs take the data from the CSV file and combine it with a simple <code class="language-plaintext highlighter-rouge">LogisticRegression</code> model and see how well we can predict the <code class="language-plaintext highlighter-rouge">age</code> of a speaker. So to start, let‚Äôs load the data and split it into train and test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Select target
</span><span class="n">target</span> <span class="o">=</span> <span class="sh">"</span><span class="s">age</span><span class="sh">"</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">].</span><span class="n">values</span>

<span class="c1"># Select relevant features from the dataframe
</span><span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">filename</span><span class="sh">"</span><span class="p">,</span> <span class="n">target</span><span class="p">]).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Combine them with the mels strength features
</span><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">mels_strengths</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create train and test set
</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">x_te</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_te</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># Plot size of dataset
</span><span class="nf">print</span><span class="p">(</span><span class="n">x_tr</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-code">(6935, 138)
</code></pre>

<p>Now that the data is ready to be trained, let‚Äôs create the model we would like to train. For this, let‚Äôs use a <code class="language-plaintext highlighter-rouge">Pipeline</code> object, so that we can explore the advantage of certain preprocessing routines (e.g. using scalers or PCA). Furthermore, let‚Äôs use <code class="language-plaintext highlighter-rouge">GridSearchCV</code> to explore different hyper-parameter combinations, as well to perform cross-validation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">PowerTransformer</span><span class="p">,</span> <span class="n">QuantileTransformer</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Create pipeline
</span><span class="n">pipe</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">"</span><span class="s">scaler</span><span class="sh">"</span><span class="p">,</span> <span class="nc">RobustScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="sh">"</span><span class="s">pca</span><span class="sh">"</span><span class="p">,</span> <span class="nc">PCA</span><span class="p">()),</span>
        <span class="p">(</span><span class="sh">"</span><span class="s">logreg</span><span class="sh">"</span><span class="p">,</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="sh">"</span><span class="s">balanced</span><span class="sh">"</span><span class="p">)),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Create grid
</span><span class="n">grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">scaler</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="nc">RobustScaler</span><span class="p">(),</span> <span class="nc">PowerTransformer</span><span class="p">(),</span> <span class="nc">QuantileTransformer</span><span class="p">()],</span>
    <span class="sh">"</span><span class="s">pca</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="nc">PCA</span><span class="p">(</span><span class="mf">0.99</span><span class="p">)],</span>
    <span class="sh">"</span><span class="s">logreg__C</span><span class="sh">"</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">16</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># Create GridSearchCV
</span><span class="n">grid_cv</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train GridSearchCV
</span><span class="n">model</span> <span class="o">=</span> <span class="n">grid_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>

<span class="c1"># Collect results in a DataFrame
</span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">grid_cv</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">)</span>

<span class="c1"># Select the columns we are interested in
</span><span class="n">col_of_interest</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">param_scaler</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">param_pca</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">param_logreg__C</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">mean_test_score</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">mean_train_score</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">std_test_score</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">std_train_score</span><span class="sh">"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="n">col_of_interest</span><span class="p">]</span>

<span class="c1"># Show the dataframe sorted according to our performance metric
</span><span class="n">cv_results</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">"</span><span class="s">mean_test_score</span><span class="sh">"</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>
<pre><code class="language-code">Fitting 4 folds for each of 96 candidates, totalling 384 fits
</code></pre>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>param_scaler</th>
      <th>param_pca</th>
      <th>param_logreg__C</th>
      <th>mean_test_score</th>
      <th>mean_train_score</th>
      <th>std_test_score</th>
      <th>std_train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>PowerTransformer()</td>
      <td>None</td>
      <td>1.0</td>
      <td>0.439508</td>
      <td>0.485124</td>
      <td>0.005489</td>
      <td>0.005539</td>
    </tr>
    <tr>
      <td>PowerTransformer()</td>
      <td>None</td>
      <td>0.464159</td>
      <td>0.438499</td>
      <td>0.483538</td>
      <td>0.005958</td>
      <td>0.003447</td>
    </tr>
    <tr>
      <td>RobustScaler()</td>
      <td>None</td>
      <td>0.464159</td>
      <td>0.437203</td>
      <td>0.481663</td>
      <td>0.007420</td>
      <td>0.005240</td>
    </tr>
    <tr>
      <td>PowerTransformer()</td>
      <td>None</td>
      <td>0.1</td>
      <td>0.436482</td>
      <td>0.473059</td>
      <td>0.005968</td>
      <td>0.003246</td>
    </tr>
    <tr>
      <td>PowerTransformer()</td>
      <td>None</td>
      <td>0.215443</td>
      <td>0.436192</td>
      <td>0.478923</td>
      <td>0.005446</td>
      <td>0.004047</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>RobustScaler()</td>
      <td>PCA(0.99)</td>
      <td>0.001</td>
      <td>0.296178</td>
      <td>0.310118</td>
      <td>0.004719</td>
      <td>0.001384</td>
    </tr>
    <tr>
      <td>QuantileTransformer()</td>
      <td>None</td>
      <td>0.002154</td>
      <td>0.291420</td>
      <td>0.297573</td>
      <td>0.005419</td>
      <td>0.001818</td>
    </tr>
    <tr>
      <td>QuantileTransformer()</td>
      <td>PCA(0.99)</td>
      <td>0.002154</td>
      <td>0.290699</td>
      <td>0.296563</td>
      <td>0.005288</td>
      <td>0.002046</td>
    </tr>
    <tr>
      <td>QuantileTransformer()</td>
      <td>None</td>
      <td>0.001</td>
      <td>0.287959</td>
      <td>0.291613</td>
      <td>0.004569</td>
      <td>0.001804</td>
    </tr>
    <tr>
      <td>QuantileTransformer()</td>
      <td>PCA(0.99)</td>
      <td>0.001</td>
      <td>0.287670</td>
      <td>0.290988</td>
      <td>0.005001</td>
      <td>0.001787</td>
    </tr>
  </tbody>
</table>
<p>96 rows √ó 7 columns</p>
</div>

<p>As an addition to the DataFrame output above, we can also plot the performance score as a function of the explored hyperparameters. However, given that we have multiple scalers and PCA approaches, we need to create a separate plot for each separate combination of hyperparameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="c1"># Establish combinations of different hyperparameters, that isn't the one
# we want to plot on the x-axis
</span><span class="n">combinations</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">product</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="sh">"</span><span class="s">scaler</span><span class="sh">"</span><span class="p">],</span> <span class="n">grid</span><span class="p">[</span><span class="sh">"</span><span class="s">pca</span><span class="sh">"</span><span class="p">]))</span>

<span class="c1"># Creates a figure with multiple subplot
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span>
    <span class="nf">len</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="sh">"</span><span class="s">scaler</span><span class="sh">"</span><span class="p">]),</span> <span class="nf">len</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="sh">"</span><span class="s">pca</span><span class="sh">"</span><span class="p">]),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Extract useful information about max performance
</span><span class="n">max_score</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="sh">"</span><span class="s">mean_test_score</span><span class="sh">"</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span>
<span class="n">c_values</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="sh">"</span><span class="s">param_logreg__C</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># Loop through the subplots and populate them
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">combinations</span><span class="p">):</span>

    <span class="c1"># Select subplot relevant grid search results
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">logical_and</span><span class="p">(</span>
        <span class="n">cv_results</span><span class="p">[</span><span class="sh">"</span><span class="s">param_pca</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">"</span><span class="s">str</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="nf">str</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
        <span class="n">cv_results</span><span class="p">[</span><span class="sh">"</span><span class="s">param_scaler</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">"</span><span class="s">str</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="nf">str</span><span class="p">(</span><span class="n">s</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">df_cv</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="n">mask</span><span class="p">].</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">"</span><span class="s">param_logreg__C</span><span class="sh">"</span><span class="p">).</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">"</span><span class="s">param_logreg__C</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># Select relevant axis
</span>    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span>

    <span class="c1"># Plot train and test curves
</span>    <span class="n">df_cv</span><span class="p">[[</span><span class="sh">"</span><span class="s">mean_train_score</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mean_test_score</span><span class="sh">"</span><span class="p">]].</span><span class="nf">plot</span><span class="p">(</span>
        <span class="n">logx</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s"> | </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span>
        <span class="n">df_cv</span><span class="p">.</span><span class="n">index</span><span class="p">,</span>
        <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">mean_train_score</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">std_train_score</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">mean_train_score</span><span class="sh">"</span><span class="p">]</span> <span class="o">+</span> <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">std_train_score</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span>
        <span class="n">df_cv</span><span class="p">.</span><span class="n">index</span><span class="p">,</span>
        <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">mean_test_score</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">std_test_score</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">mean_test_score</span><span class="sh">"</span><span class="p">]</span> <span class="o">+</span> <span class="n">df_cv</span><span class="p">[</span><span class="sh">"</span><span class="s">std_test_score</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,)</span>

    <span class="c1"># Plot best performance metric as dotted line
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">hlines</span><span class="p">(</span>
        <span class="n">max_score</span><span class="p">,</span> <span class="n">c_values</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">c_values</span><span class="p">.</span><span class="nf">max</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">gray</span><span class="sh">"</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="sh">"</span><span class="s">dotted</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Limit y-axis
</span><span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="mf">0.28</span><span class="p">,</span> <span class="mf">0.501</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_80_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>Taking the extra step and visualizing the performance metrics as curves often give us relevant additional information, that we wouldn‚Äôt get when we just look at the pandas DataFrame.</p>

<p>In this plot we can see that overall, the models perform equally well. Some have a quicker ‚Äòdrop-off‚Äô when we decrease the value of <code class="language-plaintext highlighter-rouge">C</code>, while other show a wider gap between train and test (here actually validation) score, especially when we don‚Äôt use <code class="language-plaintext highlighter-rouge">PCA</code>.</p>

<p>Having said all that, let‚Äôs just go ahead with the <code class="language-plaintext highlighter-rouge">best_estimator_</code> model and see how well it performs on the withheld test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Compute score of the best model on the withheld test set
</span><span class="n">best_clf</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">best_clf</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_te</span><span class="p">,</span> <span class="n">y_te</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-code">0.4354094579008074
</code></pre>

<p>That‚Äôs already a very good score. But to better understand how well our classification model performed, let‚Äôs also look at the corresponding confusion matrix. To do this, let‚Äôs create a short helper function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrices</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>

    <span class="c1"># Create two subplots
</span>    <span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="c1"># Specify labels
</span>    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">teens</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">twenties</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">thirties</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">fourties</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">fifties</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sixties</span><span class="sh">"</span><span class="p">]</span>

    <span class="c1"># Plots the standard confusion matrix
</span>    <span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Confusion Matrix (counts)</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">ConfusionMatrixDisplay</span><span class="p">.</span><span class="nf">from_predictions</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">xticks_rotation</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>

    <span class="c1"># Plots the normalized confusion matrix
</span>    <span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Confusion Matrix (ratios)</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">ConfusionMatrixDisplay</span><span class="p">.</span><span class="nf">from_predictions</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">xticks_rotation</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Compute test set predictions
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">best_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">x_te</span><span class="p">)</span>

<span class="c1"># Plot confusion matrices
</span><span class="nf">plot_confusion_matrices</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</code></pre></div></div>

<p><img class="img-fluid rounded z-depth-1" src="/assets/nb/04_audio_data_analysis/output_84_0.png" data-zoomable="" width="800px" style="padding-top: 20px; padding-right: 20px; padding-bottom: 20px; padding-left: 20px"></p>

<p>As you can see, while the model was able to detect more <code class="language-plaintext highlighter-rouge">twenties</code> samples than others (left confusion matrix), it overall it actually was better in classifying <code class="language-plaintext highlighter-rouge">teens</code> and <code class="language-plaintext highlighter-rouge">sixties</code> entries (e.g. with an accuracy of 59% and 55% respectively).</p>

<h1 id="summary">Summary</h1>

<p>In this unit we first saw what audio data looks like, in which different forms it can be transformed to, how it can be cleaned and explored and how it then can be used to train some machine learning models.</p>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2025 Michael P. Notter.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-126030922-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-126030922-1');
</script>






</html>
